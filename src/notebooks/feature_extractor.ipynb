{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "542c725e",
   "metadata": {},
   "source": [
    "# Image and Text Feature Extractor for RIMAS dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830fd3f",
   "metadata": {},
   "source": [
    "## Setup and libraries imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23175f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4750961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "sys.path.append(str(Path(os.getcwd()).resolve().parent.parent))\n",
    "\n",
    "from src.core.config.config import Config\n",
    "from src.ml.embeddings.feature_extractor import FeatureExtractor\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5790d94c",
   "metadata": {},
   "source": [
    "## Research Workflow: Image & Text Feature Extraction\n",
    "\n",
    "### Goal\n",
    "\n",
    "Identify the most effective feature extraction method (for both images and text) by experimenting with multiple approaches and comparing classification performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Image Feature Extraction\n",
    "\n",
    "### Methods to Compare\n",
    "\n",
    "* Flattening approach\n",
    "* HOG (Histogram of Oriented Gradients)\n",
    "* LBP (Local Binary Patterns)\n",
    "* SIFT (Scale-Invariant Feature Transform)\n",
    "* SURF (Speeded-Up Robust Features)\n",
    "* (Optional: add more methods)\n",
    "\n",
    "### Workflow\n",
    "\n",
    "1. Extract features using each method.\n",
    "2. Construct a consolidated `DataFrame` with all feature sets.\n",
    "3. Train classification models on each feature representation.\n",
    "4. Evaluate classifiers on the task: detecting the presence of specific letters in word images.\n",
    "5. Compare metrics across models and methods.\n",
    "6. Select the best-performing image feature extractor.\n",
    "\n",
    "---\n",
    "\n",
    "## Text Feature Extraction\n",
    "\n",
    "### Starting Point\n",
    "\n",
    "* Bag of letters representation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Implement bag of letters as baseline.\n",
    "2. Experiment with additional encoders (TF-IDF, n-grams, etc.).\n",
    "3. Train classifiers on text-based features.\n",
    "4. Evaluate and compare performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "* **Metrics:** Accuracy, Precision, Recall, F1-score (and others if needed).\n",
    "* **Outcome:** Best image feature extractor + best text feature extractor → Final approaches for classification tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9d093e",
   "metadata": {},
   "source": [
    "### Flatten Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3780a1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:core.loaders.data_loader:Loaded 28475 text-image pairs\n",
      "100%|██████████| 100/100 [00:04<00:00, 24.79it/s]\n",
      "INFO:utils.saving_utils.save_embeddings:Image embeddings saved to /home/nikolay/Deloitte/RIMAS/src/data/processed/words/weights/image_embeddings.parquet successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'image_embedding': array([19.508982 , 15.610779 , 11.281437 , 14.832335 , 13.826347 ,\n",
      "       13.017964 , 13.275449 , 19.233534 , 55.017963 , 29.550898 ,\n",
      "       11.934132 ,  8.8503   , 14.42515  , 18.712574 , 23.838324 ,\n",
      "       36.407185 , 35.269463 , 14.886228 ,  7.3293414, 18.233534 ,\n",
      "       44.09581  , 34.976048 , 26.964071 , 29.365269 , 13.598803 ,\n",
      "        8.095808 ,  8.7365265, 17.862276 , 37.497005 , 25.898203 ,\n",
      "       20.592813 , 16.57485  , 34.45509  , 13.646707 , 13.8503   ,\n",
      "       18.532934 , 18.479042 , 19.173653 , 14.48503  , 20.33533  ,\n",
      "       95.628746 , 32.035927 , 19.886227 , 23.221558 , 23.886227 ,\n",
      "       25.628742 , 27.706587 , 48.526947 , 60.79042  , 29.976048 ,\n",
      "       17.54491  , 33.221558 , 67.17365  , 45.38922  , 30.622755 ,\n",
      "       29.58084  , 16.443113 , 12.838324 , 15.311378 , 28.508982 ,\n",
      "       55.353294 , 28.994013 , 18.323353 , 17.035929 , 34.54491  ,\n",
      "       16.772455 , 14.652695 , 20.82036  , 18.467066 , 17.221558 ,\n",
      "       14.251497 , 16.257484 , 95.21557  , 44.796406 , 25.263474 ,\n",
      "       25.227545 , 25.131737 , 21.736526 , 21.73054  , 30.682634 ,\n",
      "       59.60479  , 27.26946  , 30.33533  , 44.718563 , 69.65868  ,\n",
      "       35.101795 , 18.628742 , 28.401197 , 16.922155 , 15.63473  ,\n",
      "       16.167665 , 32.257484 , 58.988026 , 28.227545 , 15.       ,\n",
      "       11.724551 , 19.263474 , 18.646708 , 14.203593 , 14.341317 ,\n",
      "       15.0239525,  9.676646 , 10.035928 , 14.2634735, 58.437126 ,\n",
      "       40.443115 , 24.538921 , 18.215569 , 17.131737 ,  7.3592815,\n",
      "        9.491018 , 21.502995 , 39.676647 , 37.287426 , 29.047905 ,\n",
      "       30.69461  , 44.826347 , 19.874252 ,  7.7784433,  9.964072 ,\n",
      "       14.251497 , 15.077845 , 17.952095 , 25.287426 , 41.09581  ,\n",
      "       22.08982  , 11.419162 ,  8.0239525], dtype=float32), 'label': \"l'expression\", 'image_path': '/home/nikolay/Deloitte/RIMAS/src/data/processed/words/word/l_expression_00092.png'}]\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor(\n",
    "    dataset_path=config.DATASET_PATH,\n",
    "    target_size=config.TARGET_SIZE,\n",
    "    image_embeddings_path=config.IMAGE_EMBEDDINGS_PATH,\n",
    "    encoder_type=config.ENCODER_TYPE,\n",
    "    load_flag=False\n",
    ")\n",
    "\n",
    "print(feature_extractor.image_embeddings_list[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67bdb69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rimas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
